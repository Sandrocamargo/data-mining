{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tgMtxMh1I5U"
      },
      "source": [
        "# Classification using ANN\n",
        "### Author: Prof. Sandro Camargo <github.com/sandrocamargo>\n",
        "### Data Mining Course <https://moodle.unipampa.edu.br/moodle/course/view.php?id=5213>\n",
        "#### This script uses the basic concepts of ANN.\n",
        "##### In this script, we used the iris dataset https://archive.ics.uci.edu/dataset/53/iris\n",
        "\n",
        "To open this notebook in your Google Colab environment, [click here](http://colab.research.google.com/github/Sandrocamargo/data-mining/blob/main/Python/md05_Classification_ANN.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4k27LjYoZ7H"
      },
      "outputs": [],
      "source": [
        "# Download and unzip the dataset\n",
        "!wget -c https://archive.ics.uci.edu/static/public/53/iris.zip\n",
        "!unzip -u iris.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HCGupUW4zGl"
      },
      "outputs": [],
      "source": [
        "# import and inspect the dataset\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('iris.data', header=None)\n",
        "data.columns = ['Sepal Length','Sepal Width','Petal Length','Petal Width','Species']\n",
        "data.head() # Show first 5 samples"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting to know your data\",\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.pairplot(data, hue='Species', markers=[\"o\", \"s\", \"D\"])\n",
        "plt.savefig(\"iris-pairplot.pdf\")"
      ],
      "metadata": {
        "id": "IEkzj7ecovAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_JVscN2MC4u"
      },
      "outputs": [],
      "source": [
        "# split dataset into train and test sets\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Store the inputs in the matrix X and the outputs in the array y\n",
        "X = data.iloc[:,0:4]\n",
        "print(X.describe())\n",
        "\n",
        "y = data.iloc[:,4]\n",
        "print(\"\\n\",y.value_counts(),\"\\n\")\n",
        "\n",
        "target_names = list(set(y))\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "y_bin = lb.fit_transform(y)\n",
        "\n",
        "train_x, test_x, train_y, test_y = model_selection.train_test_split(X, y_bin, train_size=0.8, stratify=y, random_state=10)\n",
        "\n",
        "# Verifying dataset dimensions\n",
        "print('The training dataset (inputs) dimensions are: ', train_x.shape)\n",
        "print('The training dataset (outputs) dimensions are: ', train_y.shape)\n",
        "print('The testing dataset (inputs) dimensions are: ', test_x.shape)\n",
        "print('The testing dataset (outputs) dimensions are: ', test_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3DG7v1bMEb1"
      },
      "outputs": [],
      "source": [
        "# Classification report on training set\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10,), max_iter=5000, random_state=1, verbose=True)\n",
        "clf.fit(train_x, train_y)\n",
        "\n",
        "# Predict back on train set to check\n",
        "predicted_train_y = clf.predict(train_x)\n",
        "predicted_labels = np.argmax(predicted_train_y, axis=1)  # convert from one-hot to class index\n",
        "\n",
        "# Recover class labels from indices\n",
        "class_labels = lb.classes_[predicted_labels]\n",
        "\n",
        "# Copy train_x for safe plotting\n",
        "tmpdata = train_x.copy()\n",
        "tmpdata['Species'] = class_labels\n",
        "\n",
        "ax = sns.scatterplot(data=tmpdata, x='Petal Width', y='Petal Length', hue='Species', style='Species')\n",
        "\n",
        "plt.title(\"Iris - Training Data\")\n",
        "plt.savefig(\"iris-train-ann.pdf\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training loss\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(clf.loss_curve_, label='Training Loss')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"MLPClassifier Training Loss Curve\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"iris-loss-curve.pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report on training set\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "predicted = clf.predict(train_x.iloc[:,0:4])\n",
        "\n",
        "print(\"Confusion Matrix:\\n\",confusion_matrix(np.argmax(train_y, axis=1), np.argmax(predicted, axis=1)))\n",
        "\n",
        "print(classification_report(np.argmax(train_y, axis=1), np.argmax(predicted, axis=1), target_names=target_names))"
      ],
      "metadata": {
        "id": "790opR_ZJZnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict back on train set to check\n",
        "predicted_test_y = clf.predict(test_x)\n",
        "predicted_labels = np.argmax(predicted_test_y, axis=1)  # convert from one-hot to class index\n",
        "\n",
        "# Recover class labels from indices\n",
        "class_labels = lb.classes_[predicted_labels]\n",
        "\n",
        "# Showing the performance on testing set\n",
        "tmpdata = test_x.copy()\n",
        "tmpdata['Species'] = class_labels\n",
        "\n",
        "# Plotting the training set\n",
        "ax = sns.scatterplot(data=tmpdata, x='Petal Width', y='Petal Length', hue='Species', style='Species')\n",
        "\n",
        "plt.title(\"Iris - Test Data\")\n",
        "plt.savefig(\"iris-test-knn.pdf\")"
      ],
      "metadata": {
        "id": "fjvKlO_SpPT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSKGxaAETqYM"
      },
      "outputs": [],
      "source": [
        "# Showing the performance on testing set\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predicted = clf.predict(test_x.iloc[:,0:4])\n",
        "\n",
        "print(\"Confusion Matrix:\\n\",confusion_matrix(np.argmax(test_y, axis=1), np.argmax(predicted, axis=1)))\n",
        "\n",
        "print(classification_report(np.argmax(test_y, axis=1), np.argmax(predicted, axis=1), target_names=target_names))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}